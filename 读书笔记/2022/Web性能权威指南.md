# Web性能权威指南

## 网络延迟的构成

**传播延迟**

*消息从发送端到接收端需要的时间，是信号传播距离和速度的函数*

**传输延迟**

*把消息中的所有比特转移到链路中需要的时间，是消息长度和链路速率的函数*

**处理延迟**

*处理分组首部、检查位错误及确定分组目标所需的时间*

**排队延迟**

*到来的分组排队等待处理的时间*

> 只要一条简单的traceroute命令，就能知道上网服务商的拓扑结构和速度。在Unix平台上，可以在命令行运行traceroute。而在Windows平台中，相应的命令叫tracert。
> 

## TCP性能检查清单

优化TCP性能的回报是丰厚的，无论什么应用，性能提升可以在与服务器的每个连接中体现出来。下面几条请大家务必记在自己的日程表里：

- 把服务器内核升级到最新版本（Linux：3.2+）
- 确保cwnd大小为10
- 禁用空闲后的慢启动
- 确保启动窗口缩放；
- 减少传输冗余数
- 压缩要传输的数据
- 把服务器放到离用户近的地方以减少往返时间
- 尽最大可能重用已经建立的TCP连接

## UDP无服务概念

<aside>
💡 UDP数据报中的源端口和校验和字段都是可选的。IP分组的首部也有校验和，应用程序可以忽略UDP校验和。也就是说，所有错误检测和错误纠正工作都可以委托给上层的应用程序。说到底，UDP仅仅是在IP层之上通过嵌入应用程序的源端口和目标端口，提供了一个“应用程序多路复用”机制。

</aside>

**不保证消息交付**

*不确认，不重传，无超时*。

**不保证交付顺序**

*不设置包序号，不重排，不会发生队首阻塞。*

**不跟踪连接状态**

*不必建立连接或重启状态机。*

**不需要拥塞控制**

*不内置客户端或网络反馈机制。*

## 经典的性能优化最佳实践

<aside>
💡 无论什么网络，也不管所用网络协议是什么版本，所有应用都应该致力于消除或减少不必要的网络延迟，将需要传输的数据压缩至最少。这两条标准是经典的性能优化最佳实践，是其他数十条性能准则的出发点。

</aside>

**减少DNS查找**

*每一次主机名解析都需要一次网络往返，从而增加请求的延迟时间，同时还会阻塞后续请求。*

**重用TCP连接**

*尽可能使用持久连接，以消除TCP握手和慢启动延迟；参见2.2.2节“慢启动”。*

**减少HTTP重定向**

*HTTP重定向极费时间，特别是不同域名之间的重定向，更加费时；这里面既有额外的DNS查询、TCP握手，还有其他延迟。最佳的重定向次数为零。*

**使用CDN（内容分发网络）**

*把数据放到离用户地理位置更近的地方，可以显著减少每次TCP连接的网络延迟，增大吞吐量。这一条既适用于静态内容，也适用于动态内容*

**去掉不必要的资源**

*任何请求都不如没有请求快*

<aside>
💡 延迟是瓶颈，最快的速度莫过于什么也不传输。然而，HTTP也提供了很多额外的机制，比如缓存和压缩，还有与其版本对应的一些性能技巧。

</aside>

**在客户端缓存资源**

*应该缓存应用资源，从而避免每次请求都发送相同的内容。*

**传输压缩过的内容**

*传输前应该压缩应用资源，把要传输的字节减至最少：确保对每种要传输的资源采用最好的压缩手段。*

**消除不必要的请求开销**

*减少请求的HTTP首部数据（比如HTTP cookie），节省的时间相当于几次往返的延迟时间。*

**并行处理请求和响应**

*请求和响应的排队都会导致延迟，无论是客户端还是服务器端。这一点经常被忽视，但却会无谓地导致很长延迟。*

**针对协议版本采取优化措施**

*HTTP 1.x支持有限的并行机制，要求打包资源、跨域分散资源，等等。相对而言，HTTP 2.0只要建立一个连接就能实现最优性能，同时无需针对HTTP 1.x的那些优化方法。*

## 针对HTTP 1.x的优化建议

<aside>
💡 针对HTTP 1.x的优化次序很重要：首先要配置服务器以最大限度地保证TCP和TLS的性能最优，然后再谨慎地选择和采用移动及经典的应用最佳实践，之后再度量，迭代。采用了经典的应用优化措施和适当的性能度量手段，还要进一步评估是否有必要为应用采取特定于HTTP 1.x的优化措施（其实是权宜之计）。

</aside>

**利用HTTP管道**

*如果你的应用可以控制客户端和服务器这两端，那么使用管道可以显著减少网络延迟。*

**采用域名分区**

*如果你的应用性能受限于默认的每来源6个连接，可以考虑将资源分散到多个来源。*

**打包资源以减少HTTP请求**

*拼接和精灵图等技巧有助于降低协议开销，又能达成类似管道的性能提升。*

**嵌入小资源**

*考虑直接在父文档中嵌入小资源，从而减少请求数量。*

## 针对HTTP 2.0的优化建议

### 去掉对1.x的优化

<aside>
💡 针对HTTP 2.0和HTTP 1.x的优化策略没有什么重叠。因此，不仅不必担心HTTP 1.x协议的种种限制，而且要撤销原先那些必要的做法。要获得最佳性能，应该尽可能把所有资源都集中在一个域名之下。域名分区在HTTP 2.0之下属于反模式，对发挥协议的性能有害：分区是开始，之后影响会逐渐扩散。打包资源不会影响HTTP 2.0协议本身，但对缓存性能和执行速度有负面影响。

</aside>

**每个来源使用一个连接**

*HTTP 2.0通过将一个TCP连接的吞吐量最大化来提升性能。事实上，在HTTP 2.0之下再使用多个连接（比如域名分区）反倒成了一种反模式，因为多个连接会抵消新协议中首部压缩和请求优先级的效用。*

**去掉不必要的文件合并和图片拼接**

*打包资源的缺点很多，比如缓存失效、占用内存、延缓执行，以及增加应用复杂性。有了HTTP 2.0，很多小资源都可以并行发送，导致打包资源的效率反而更低。*

**利用服务器推送**

*之前针对HTTP 1.x而嵌入的大多数资源，都可以而且应该通过服务器推送来交付。这样一来，客户端就可以分别缓存每个资源，并在页面间实现重用，而不必把它们放到每个页面里了。*

### 双协议应用策略

**相同的应用代码，双协议部署**

*相同的应用代码可能通过HTTP 1.x也可能通过HTTP 2.0交付。可能任何一种协议之下都达不到最佳性能，但可以追求性能足够好。所谓足够好，需要通过针对每一种应用单独度量来保证。这种情况下，第一步可以先撤销域名分区以实现HTTP 2.0交付。然后，随着更多用户迁移到HTTP 2.0，可以继续撤销资源打包并尽可能利用服务器推送。*

**分离应用代码，双协议部署**

*根据协议不同分别交付不同版本的应用。这样会增加运维的复杂性，但实践中对很多应用倒是十分可行。比如，一台负责完成连接的边界服务器可以根据协商后的协议版本，把客户端请求引导至适当的服务器。*

**动态HTTP 1.x和HTTP 2.0优化**

*某些自动化的Web优化框架，以及开源及商业产品，都可以在响应请求时动态重写交付的应用代码（包括连接、拼合、分区，等等)此时，服务器也可以考虑协商的协议版本，并动态采用适当的优化策略。*

**HTTP 2.0，单协议部署**

*如果应用可以控制服务器和客户端，那没理由不只使用HTTP 2.0。事实上，如果真有这种可能，那就应该专一使用HTTP 2.0。*