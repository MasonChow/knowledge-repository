# Web 性能权威指南

## 网络延迟的构成

**传播延迟**

_消息从发送端到接收端需要的时间，是信号传播距离和速度的函数_

**传输延迟**

_把消息中的所有比特转移到链路中需要的时间，是消息长度和链路速率的函数_

**处理延迟**

_处理分组首部、检查位错误及确定分组目标所需的时间_

**排队延迟**

_到来的分组排队等待处理的时间_

> 只要一条简单的 traceroute 命令，就能知道上网服务商的拓扑结构和速度。在 Unix 平台上，可以在命令行运行 traceroute。而在 Windows 平台中，相应的命令叫 tracert。

## TCP 性能检查清单

优化 TCP 性能的回报是丰厚的，无论什么应用，性能提升可以在与服务器的每个连接中体现出来。下面几条请大家务必记在自己的日程表里：

- 把服务器内核升级到最新版本（Linux：3.2+）
- 确保 cwnd 大小为 10
- 禁用空闲后的慢启动
- 确保启动窗口缩放；
- 减少传输冗余数
- 压缩要传输的数据
- 把服务器放到离用户近的地方以减少往返时间
- 尽最大可能重用已经建立的 TCP 连接

## UDP 无服务概念

<aside>
💡 UDP数据报中的源端口和校验和字段都是可选的。IP分组的首部也有校验和，应用程序可以忽略UDP校验和。也就是说，所有错误检测和错误纠正工作都可以委托给上层的应用程序。说到底，UDP仅仅是在IP层之上通过嵌入应用程序的源端口和目标端口，提供了一个“应用程序多路复用”机制。

</aside>

**不保证消息交付**

_不确认，不重传，无超时_。

**不保证交付顺序**

_不设置包序号，不重排，不会发生队首阻塞。_

**不跟踪连接状态**

_不必建立连接或重启状态机。_

**不需要拥塞控制**

_不内置客户端或网络反馈机制。_

## 经典的性能优化最佳实践

<aside>
💡 无论什么网络，也不管所用网络协议是什么版本，所有应用都应该致力于消除或减少不必要的网络延迟，将需要传输的数据压缩至最少。这两条标准是经典的性能优化最佳实践，是其他数十条性能准则的出发点。

</aside>

**减少 DNS 查找**

_每一次主机名解析都需要一次网络往返，从而增加请求的延迟时间，同时还会阻塞后续请求。_

**重用 TCP 连接**

_尽可能使用持久连接，以消除 TCP 握手和慢启动延迟；参见 2.2.2 节“慢启动”。_

**减少 HTTP 重定向**

_HTTP 重定向极费时间，特别是不同域名之间的重定向，更加费时；这里面既有额外的 DNS 查询、TCP 握手，还有其他延迟。最佳的重定向次数为零。_

**使用 CDN（内容分发网络）**

_把数据放到离用户地理位置更近的地方，可以显著减少每次 TCP 连接的网络延迟，增大吞吐量。这一条既适用于静态内容，也适用于动态内容_

**去掉不必要的资源**

_任何请求都不如没有请求快_

<aside>
💡 延迟是瓶颈，最快的速度莫过于什么也不传输。然而，HTTP也提供了很多额外的机制，比如缓存和压缩，还有与其版本对应的一些性能技巧。

</aside>

**在客户端缓存资源**

_应该缓存应用资源，从而避免每次请求都发送相同的内容。_

**传输压缩过的内容**

_传输前应该压缩应用资源，把要传输的字节减至最少：确保对每种要传输的资源采用最好的压缩手段。_

**消除不必要的请求开销**

_减少请求的 HTTP 首部数据（比如 HTTP cookie），节省的时间相当于几次往返的延迟时间。_

**并行处理请求和响应**

_请求和响应的排队都会导致延迟，无论是客户端还是服务器端。这一点经常被忽视，但却会无谓地导致很长延迟。_

**针对协议版本采取优化措施**

_HTTP 1.x 支持有限的并行机制，要求打包资源、跨域分散资源，等等。相对而言，HTTP 2.0 只要建立一个连接就能实现最优性能，同时无需针对 HTTP 1.x 的那些优化方法。_

## 针对 HTTP 1.x 的优化建议

<aside>
💡 针对HTTP 1.x的优化次序很重要：首先要配置服务器以最大限度地保证TCP和TLS的性能最优，然后再谨慎地选择和采用移动及经典的应用最佳实践，之后再度量，迭代。采用了经典的应用优化措施和适当的性能度量手段，还要进一步评估是否有必要为应用采取特定于HTTP 1.x的优化措施（其实是权宜之计）。

</aside>

**利用 HTTP 管道**

_如果你的应用可以控制客户端和服务器这两端，那么使用管道可以显著减少网络延迟。_

**采用域名分区**

_如果你的应用性能受限于默认的每来源 6 个连接，可以考虑将资源分散到多个来源。_

**打包资源以减少 HTTP 请求**

_拼接和精灵图等技巧有助于降低协议开销，又能达成类似管道的性能提升。_

**嵌入小资源**

_考虑直接在父文档中嵌入小资源，从而减少请求数量。_

## 针对 HTTP 2.0 的优化建议

### 去掉对 1.x 的优化

<aside>
💡 针对HTTP 2.0和HTTP 1.x的优化策略没有什么重叠。因此，不仅不必担心HTTP 1.x协议的种种限制，而且要撤销原先那些必要的做法。要获得最佳性能，应该尽可能把所有资源都集中在一个域名之下。域名分区在HTTP 2.0之下属于反模式，对发挥协议的性能有害：分区是开始，之后影响会逐渐扩散。打包资源不会影响HTTP 2.0协议本身，但对缓存性能和执行速度有负面影响。

</aside>

**每个来源使用一个连接**

_HTTP 2.0 通过将一个 TCP 连接的吞吐量最大化来提升性能。事实上，在 HTTP 2.0 之下再使用多个连接（比如域名分区）反倒成了一种反模式，因为多个连接会抵消新协议中首部压缩和请求优先级的效用。_

**去掉不必要的文件合并和图片拼接**

_打包资源的缺点很多，比如缓存失效、占用内存、延缓执行，以及增加应用复杂性。有了 HTTP 2.0，很多小资源都可以并行发送，导致打包资源的效率反而更低。_

**利用服务器推送**

_之前针对 HTTP 1.x 而嵌入的大多数资源，都可以而且应该通过服务器推送来交付。这样一来，客户端就可以分别缓存每个资源，并在页面间实现重用，而不必把它们放到每个页面里了。_

### 双协议应用策略

**相同的应用代码，双协议部署**

_相同的应用代码可能通过 HTTP 1.x 也可能通过 HTTP 2.0 交付。可能任何一种协议之下都达不到最佳性能，但可以追求性能足够好。所谓足够好，需要通过针对每一种应用单独度量来保证。这种情况下，第一步可以先撤销域名分区以实现 HTTP 2.0 交付。然后，随着更多用户迁移到 HTTP 2.0，可以继续撤销资源打包并尽可能利用服务器推送。_

**分离应用代码，双协议部署**

_根据协议不同分别交付不同版本的应用。这样会增加运维的复杂性，但实践中对很多应用倒是十分可行。比如，一台负责完成连接的边界服务器可以根据协商后的协议版本，把客户端请求引导至适当的服务器。_

**动态 HTTP 1.x 和 HTTP 2.0 优化**

_某些自动化的 Web 优化框架，以及开源及商业产品，都可以在响应请求时动态重写交付的应用代码（包括连接、拼合、分区，等等)此时，服务器也可以考虑协商的协议版本，并动态采用适当的优化策略。_

**HTTP 2.0，单协议部署**

_如果应用可以控制服务器和客户端，那没理由不只使用 HTTP 2.0。事实上，如果真有这种可能，那就应该专一使用 HTTP 2.0。_
